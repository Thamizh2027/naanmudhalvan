{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thamizh2027/naanmudhalvan/blob/main/Copy_of_Twitter_sentiment_Extaction_Analysis%2CEDA_and_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "rohitsingh9990_tse_spacy_model_path = kagglehub.dataset_download('rohitsingh9990/tse-spacy-model')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GEFl1qoC0bDY",
        "outputId": "b506be49-e716-468d-8213-1e5fe7cf87a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rohitsingh9990/tse-spacy-model?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15.4M/15.4M [00:00<00:00, 123MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "C1Ote_990bDa"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Necesseties"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "Q6YvKGzv0bDb"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from collections import Counter\n",
        "\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import nltk\n",
        "import spacy\n",
        "import random\n",
        "from spacy.util import compounding\n",
        "from spacy.util import minibatch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85ZJuuCX0bDc"
      },
      "cell_type": "markdown",
      "source": [
        "**Below is a helper Function which generates random colors which can be used to give different colors to your plots.Feel free to use it**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "DjwLW81R0bDc"
      },
      "cell_type": "code",
      "source": [
        "def random_colours(number_of_colors):\n",
        "    '''\n",
        "    Simple function for random colours generation.\n",
        "    Input:\n",
        "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
        "    Output:\n",
        "        Color in the following format: ['#E86DA4'] .\n",
        "    '''\n",
        "    colors = []\n",
        "    for i in range(number_of_colors):\n",
        "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
        "    return colors"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_dA4OnY0bDd"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading the Data"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "_kg_hide-input": true,
        "id": "ELA1QjWo0bDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "e4ae09e7-bf7f-4113-92cc-17e0b04e3a2b"
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
        "ss = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/tweet-sentiment-extraction/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5ee6c6647bab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/tweet-sentiment-extraction/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/tweet-sentiment-extraction/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/tweet-sentiment-extraction/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/tweet-sentiment-extraction/train.csv'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "id": "ItB55S400bDe"
      },
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1tyqV8N0bDf"
      },
      "cell_type": "markdown",
      "source": [
        "So We have 27486 tweets in the train set and 3535 tweets in the test set"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "id": "qSJJoYCR0bDf"
      },
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyvT9cGQ0bDg"
      },
      "cell_type": "markdown",
      "source": [
        "We have one null Value in the train , as the test field for value is NAN we will just remove it"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_Vvd-dQ00bDg"
      },
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "id": "RtSBmBr30bDh"
      },
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ae3UbBub0bDh"
      },
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "id": "CWKcavqI0bDh"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGpk0vjl0bDh"
      },
      "cell_type": "markdown",
      "source": [
        "Selected_text is a subset of text"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": false,
        "id": "JwJcnnEb0bDh"
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5lFUEKt0bDi"
      },
      "cell_type": "markdown",
      "source": [
        "Lets look at the distribution of tweets in the train set"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "IVaujZ0B0bDi"
      },
      "cell_type": "code",
      "source": [
        "temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n",
        "temp.style.background_gradient(cmap='Purples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "W0eMOViN0bDi"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='sentiment',data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCUARuQr0bDi"
      },
      "cell_type": "markdown",
      "source": [
        "Let's draw a Funnel-Chart for better visualization"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "JmjAqkBz0bDi"
      },
      "cell_type": "code",
      "source": [
        "fig = go.Figure(go.Funnelarea(\n",
        "    text =temp.sentiment,\n",
        "    values = temp.text,\n",
        "    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n",
        "    ))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EN4SPHUE0bDi"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating Meta-Features"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "vqu14fwX0bDj"
      },
      "cell_type": "code",
      "source": [
        "def jaccard(str1, str2):\n",
        "    a = set(str1.lower().split())\n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "OmSmJbFe0bDj"
      },
      "cell_type": "code",
      "source": [
        "results_jaccard=[]\n",
        "\n",
        "for ind,row in train.iterrows():\n",
        "    sentence1 = row.text\n",
        "    sentence2 = row.selected_text\n",
        "\n",
        "    jaccard_score = jaccard(sentence1,sentence2)\n",
        "    results_jaccard.append([sentence1,sentence2,jaccard_score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "eXVvn1sd0bDj"
      },
      "cell_type": "code",
      "source": [
        "jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\n",
        "train = train.merge(jaccard,how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "RlFATbCn0bDj"
      },
      "cell_type": "code",
      "source": [
        "train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\n",
        "train['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\n",
        "train['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ltK3cBBa0bDj"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDZltM6D0bDj"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at the distribution of Meta-Features"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "vmkcad0R0bDk"
      },
      "cell_type": "code",
      "source": [
        "hist_data = [train['Num_words_ST'],train['Num_word_text']]\n",
        "\n",
        "group_labels = ['Selected_Text', 'Text']\n",
        "\n",
        "# Create distplot with custom bin_size\n",
        "fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n",
        "fig.update_layout(title_text='Distribution of Number Of words')\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=900,\n",
        "    height=700,\n",
        "    paper_bgcolor=\"LightSteelBlue\",\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9upHTuz0bDk"
      },
      "cell_type": "markdown",
      "source": [
        "* The number of words plot is really interesting ,the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UGNscMKT0bDk"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n",
        "p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTmhmUvM0bDk"
      },
      "cell_type": "markdown",
      "source": [
        "**Now It will be more interesting to see the differnce in number of words and jaccard_scores across different Sentiments**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "RnO6SjeU0bDk"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "p1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n",
        "p2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "b3UuG95S0bDk"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pumLC7zF0bDp"
      },
      "cell_type": "markdown",
      "source": [
        "I was not able to plot kde plot for neutral tweets because most of the values for difference in number of words were zero. We can see it clearly now ,if we had used the feature in the starting we would have known that text and selected text are mostly the same for neutral tweets,thus its always important to keep the end goal in mind while performing EDA"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PIfr-Bki0bDq"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "p1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\n",
        "p2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\n",
        "plt.legend(labels=['positive','negative'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQK8eLUL0bDq"
      },
      "cell_type": "markdown",
      "source": [
        "I was not able to plot kde of jaccard_scores of neutral tweets for the same reason,thus I will plot a distribution plot"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mfXoAZtD0bDq"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "utZDBej90bDr"
      },
      "cell_type": "code",
      "source": [
        "k = train[train['Num_word_text']<=2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ug-F4EQI0bDr"
      },
      "cell_type": "code",
      "source": [
        "k.groupby('sentiment').mean()['jaccard_score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDjU6JFB0bDr"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that there is similarity between text and selected text .Let's have closer look"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ouhRv-jL0bDr"
      },
      "cell_type": "code",
      "source": [
        "k[k['sentiment']=='positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEcjoIwE0bDs"
      },
      "cell_type": "markdown",
      "source": [
        "### Cleaning the Corpus\n",
        "Now Before We Dive into extracting information out of words in text and selected text,let's first clean the data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9oIclF2s0bDs"
      },
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "FuUCaWLX0bDs"
      },
      "cell_type": "code",
      "source": [
        "train['text'] = train['text'].apply(lambda x:clean_text(x))\n",
        "train['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kfQdpZL10bDz"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNp1K8-B0bDz"
      },
      "cell_type": "markdown",
      "source": [
        "## Most Common words in our Target-Selected Text"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "l6iEKITI0bDz"
      },
      "cell_type": "code",
      "source": [
        "train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\n",
        "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
        "temp = pd.DataFrame(top.most_common(20))\n",
        "temp.columns = ['Common_words','count']\n",
        "temp.style.background_gradient(cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "oCW7aI_g0bD0"
      },
      "cell_type": "code",
      "source": [
        "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h',\n",
        "             width=700, height=700,color='Common_words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nE_h-I6E0bD0"
      },
      "cell_type": "markdown",
      "source": [
        "OOPS!While we cleaned our dataset we didnt remove the stop words and hence we can see the most coomon word is 'to' . Let's try again after removing the stopwords"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "-UmHunj20bD0"
      },
      "cell_type": "code",
      "source": [
        "def remove_stopword(x):\n",
        "    return [y for y in x if y not in stopwords.words('english')]\n",
        "train['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "ORdcd25y0bD0"
      },
      "cell_type": "code",
      "source": [
        "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
        "temp = pd.DataFrame(top.most_common(20))\n",
        "temp = temp.iloc[1:,:]\n",
        "temp.columns = ['Common_words','count']\n",
        "temp.style.background_gradient(cmap='Purples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "rPRRxmT90bD0"
      },
      "cell_type": "code",
      "source": [
        "fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwKGBXck0bD0"
      },
      "cell_type": "markdown",
      "source": [
        "# Most Common words in Text\n",
        "\n",
        "Let's also look at the most common words in Text"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "H3mgjDEf0bD1"
      },
      "cell_type": "code",
      "source": [
        "train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\n",
        "train['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "_9XJYtc80bD1"
      },
      "cell_type": "code",
      "source": [
        "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\n",
        "temp = pd.DataFrame(top.most_common(25))\n",
        "temp = temp.iloc[1:,:]\n",
        "temp.columns = ['Common_words','count']\n",
        "temp.style.background_gradient(cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCcZ0A3s0bD1"
      },
      "cell_type": "markdown",
      "source": [
        "So the first two common word was I'm so I removed it and took data from second row"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "BgevYVIW0bD1"
      },
      "cell_type": "code",
      "source": [
        "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h',\n",
        "             width=700, height=700,color='Common_words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iar2aZ5t0bD1"
      },
      "cell_type": "markdown",
      "source": [
        "SO we can see the Most common words in Selected text and Text are almost the same,which was obvious"
      ]
    },
    {
      "metadata": {
        "id": "PJsk7_tk0bD2"
      },
      "cell_type": "markdown",
      "source": [
        "# Most common words Sentiments Wise\n",
        "\n",
        "Let's look at the most common words in different sentiments"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oY5Np50V0bD2"
      },
      "cell_type": "code",
      "source": [
        "Positive_sent = train[train['sentiment']=='positive']\n",
        "Negative_sent = train[train['sentiment']=='negative']\n",
        "Neutral_sent = train[train['sentiment']=='neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "1mpDte9Z0bD2"
      },
      "cell_type": "code",
      "source": [
        "#MosT common positive words\n",
        "top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\n",
        "temp_positive = pd.DataFrame(top.most_common(20))\n",
        "temp_positive.columns = ['Common_words','count']\n",
        "temp_positive.style.background_gradient(cmap='Greens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "jkMrFFhN0bD2"
      },
      "cell_type": "code",
      "source": [
        "fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h',\n",
        "             width=700, height=700,color='Common_words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "HlecjEdk0bD2"
      },
      "cell_type": "code",
      "source": [
        "#MosT common negative words\n",
        "top = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\n",
        "temp_negative = pd.DataFrame(top.most_common(20))\n",
        "temp_negative = temp_negative.iloc[1:,:]\n",
        "temp_negative.columns = ['Common_words','count']\n",
        "temp_negative.style.background_gradient(cmap='Reds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "XjTvdKar0bD2"
      },
      "cell_type": "code",
      "source": [
        "fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "4Psx5YcF0bD3"
      },
      "cell_type": "code",
      "source": [
        "#MosT common Neutral words\n",
        "top = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\n",
        "temp_neutral = pd.DataFrame(top.most_common(20))\n",
        "temp_neutral = temp_neutral.loc[1:,:]\n",
        "temp_neutral.columns = ['Common_words','count']\n",
        "temp_neutral.style.background_gradient(cmap='Reds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "vH9slzjA0bD3"
      },
      "cell_type": "code",
      "source": [
        "fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h',\n",
        "             width=700, height=700,color='Common_words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "8zM5QbIl0bD3"
      },
      "cell_type": "code",
      "source": [
        "fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "l00TX9_20bD3"
      },
      "cell_type": "code",
      "source": [
        "raw_text = [word for word_list in train['temp_list1'] for word in word_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "rEpRtpxI0bD4"
      },
      "cell_type": "code",
      "source": [
        "def words_unique(sentiment,numwords,raw_words):\n",
        "    '''\n",
        "    Input:\n",
        "        segment - Segment category (ex. 'Neutral');\n",
        "        numwords - how many specific words do you want to see in the final result;\n",
        "        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n",
        "    Output:\n",
        "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
        "\n",
        "    '''\n",
        "    allother = []\n",
        "    for item in train[train.sentiment != sentiment]['temp_list1']:\n",
        "        for word in item:\n",
        "            allother .append(word)\n",
        "    allother  = list(set(allother ))\n",
        "\n",
        "    specificnonly = [x for x in raw_text if x not in allother]\n",
        "\n",
        "    mycounter = Counter()\n",
        "\n",
        "    for item in train[train.sentiment == sentiment]['temp_list1']:\n",
        "        for word in item:\n",
        "            mycounter[word] += 1\n",
        "    keep = list(specificnonly)\n",
        "\n",
        "    for word in list(mycounter):\n",
        "        if word not in keep:\n",
        "            del mycounter[word]\n",
        "\n",
        "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
        "\n",
        "    return Unique_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ln-HirZ_0bD4"
      },
      "cell_type": "markdown",
      "source": [
        "### Positive Tweets"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dzApETzn0bD4"
      },
      "cell_type": "code",
      "source": [
        "Unique_Positive= words_unique('positive', 20, raw_text)\n",
        "print(\"The top 20 unique words in Positive Tweets are:\")\n",
        "Unique_Positive.style.background_gradient(cmap='Greens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lF5HTHz70bD4"
      },
      "cell_type": "code",
      "source": [
        "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "6FUnzbvw0bD4"
      },
      "cell_type": "code",
      "source": [
        "from palettable.colorbrewer.qualitative import Pastel1_7\n",
        "plt.figure(figsize=(16,10))\n",
        "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
        "plt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.title('DoNut Plot Of Unique Positive Words')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZMo4IXes0bD5"
      },
      "cell_type": "code",
      "source": [
        "Unique_Negative= words_unique('negative', 10, raw_text)\n",
        "print(\"The top 10 unique words in Negative Tweets are:\")\n",
        "Unique_Negative.style.background_gradient(cmap='Reds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "52jbvH5b0bD5"
      },
      "cell_type": "code",
      "source": [
        "from palettable.colorbrewer.qualitative import Pastel1_7\n",
        "plt.figure(figsize=(16,10))\n",
        "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
        "plt.rcParams['text.color'] = 'black'\n",
        "plt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.title('DoNut Plot Of Unique Negative Words')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oq9HVg2r0bD5"
      },
      "cell_type": "code",
      "source": [
        "Unique_Neutral= words_unique('neutral', 10, raw_text)\n",
        "print(\"The top 10 unique words in Neutral Tweets are:\")\n",
        "Unique_Neutral.style.background_gradient(cmap='Oranges')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "4P_VHbQw0bD5"
      },
      "cell_type": "code",
      "source": [
        "from palettable.colorbrewer.qualitative import Pastel1_7\n",
        "plt.figure(figsize=(16,10))\n",
        "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
        "plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.title('DoNut Plot Of Unique Neutral Words')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xs8jg0b00bD5"
      },
      "cell_type": "markdown",
      "source": [
        "**By Looking at the Unique Words of each sentiment,we now have much more clarity about the data,these unique words are very strong determiners of Sentiment of tweets**"
      ]
    },
    {
      "metadata": {
        "id": "a5DT0gvo0bD5"
      },
      "cell_type": "markdown",
      "source": [
        "## It's Time For WordClouds\n",
        "\n",
        "We will be building wordclouds in the following order:\n",
        "\n",
        "* WordCloud of Neutral Tweets\n",
        "* WordCloud of Positive Tweets\n",
        "* WordCloud of Negative Tweets\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "mgHJC-Pk0bD5"
      },
      "cell_type": "code",
      "source": [
        "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n",
        "                   title = None, title_size=40, image_color=False):\n",
        "    stopwords = set(STOPWORDS)\n",
        "    more_stopwords = {'u', \"im\"}\n",
        "    stopwords = stopwords.union(more_stopwords)\n",
        "\n",
        "    wordcloud = WordCloud(background_color=color,\n",
        "                    stopwords = stopwords,\n",
        "                    max_words = max_words,\n",
        "                    max_font_size = max_font_size,\n",
        "                    random_state = 42,\n",
        "                    width=400,\n",
        "                    height=200,\n",
        "                    mask = mask)\n",
        "    wordcloud.generate(str(text))\n",
        "\n",
        "    plt.figure(figsize=figure_size)\n",
        "    if image_color:\n",
        "        image_colors = ImageColorGenerator(mask);\n",
        "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
        "        plt.title(title, fontdict={'size': title_size,\n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    else:\n",
        "        plt.imshow(wordcloud);\n",
        "        plt.title(title, fontdict={'size': title_size, 'color': 'black',\n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    plt.axis('off');\n",
        "    plt.tight_layout()\n",
        "d = '/kaggle/input/masks-for-wordclouds/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ApFfW77h0bD6"
      },
      "cell_type": "markdown",
      "source": [
        "I have added more words like im , u (that we say were there in the most common words,disturbing our analysis) as stopwords"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "c9o7-ozX0bD6"
      },
      "cell_type": "code",
      "source": [
        "pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n",
        "plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "95G8nKjx0bD7"
      },
      "cell_type": "code",
      "source": [
        "plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "xaOvfzcx0bD7"
      },
      "cell_type": "code",
      "source": [
        "plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "C8C9hflQ0bD8"
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n",
        "df_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
        "df_submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-JjrFUPi0bD8"
      },
      "cell_type": "code",
      "source": [
        "df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CvnvPr6g0bD8"
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train[df_train['Num_words_text']>=3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUIjOGuf0bD9"
      },
      "cell_type": "markdown",
      "source": [
        "**For Full Understanding of the how to train spacy NER with custom inputs, please read the spacy documentation along with the code presentation in this notebook : https://spacy.io/usage/training#ner Follow along from Updating Spacy NER**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "y-CexEPy0bD9"
      },
      "cell_type": "code",
      "source": [
        "def save_model(output_dir, nlp, new_model_name):\n",
        "    ''' This Function Saves model to\n",
        "    given output directory'''\n",
        "\n",
        "    output_dir = f'../working/{output_dir}'\n",
        "    if output_dir is not None:\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        nlp.meta[\"name\"] = new_model_name\n",
        "        nlp.to_disk(output_dir)\n",
        "        print(\"Saved model to\", output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "_v7PKIe-0bD9"
      },
      "cell_type": "code",
      "source": [
        "# pass model = nlp if you want to train on top of existing model\n",
        "\n",
        "def train(train_data, output_dir, n_iter=20, model=None):\n",
        "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
        "    \"\"\n",
        "    if model is not None:\n",
        "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
        "        print(\"Created blank 'en' model\")\n",
        "\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise, get it so we can add labels\n",
        "    else:\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "    # add labels\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        # sizes = compounding(1.0, 4.0, 1.001)\n",
        "        # batch up the examples using spaCy's minibatch\n",
        "        if model is None:\n",
        "            nlp.begin_training()\n",
        "        else:\n",
        "            nlp.resume_training()\n",
        "\n",
        "\n",
        "        for itn in tqdm(range(n_iter)):\n",
        "            random.shuffle(train_data)\n",
        "            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))\n",
        "            losses = {}\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts,  # batch of texts\n",
        "                            annotations,  # batch of annotations\n",
        "                            drop=0.5,   # dropout - make it harder to memorise data\n",
        "                            losses=losses,\n",
        "                            )\n",
        "            print(\"Losses\", losses)\n",
        "    save_model(output_dir, nlp, 'st_ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eOiELgBV0bD9"
      },
      "cell_type": "code",
      "source": [
        "def get_model_out_path(sentiment):\n",
        "    '''\n",
        "    Returns Model output path\n",
        "    '''\n",
        "    model_out_path = None\n",
        "    if sentiment == 'positive':\n",
        "        model_out_path = 'models/model_pos'\n",
        "    elif sentiment == 'negative':\n",
        "        model_out_path = 'models/model_neg'\n",
        "    return model_out_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AmksHjx20bD9"
      },
      "cell_type": "code",
      "source": [
        "def get_training_data(sentiment):\n",
        "    '''\n",
        "    Returns Trainong data in the format needed to train spacy NER\n",
        "    '''\n",
        "    train_data = []\n",
        "    for index, row in df_train.iterrows():\n",
        "        if row.sentiment == sentiment:\n",
        "            selected_text = row.selected_text\n",
        "            text = row.text\n",
        "            start = text.find(selected_text)\n",
        "            end = start + len(selected_text)\n",
        "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
        "    return train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBgucHjp0bD-"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training models for Positive and Negative tweets"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "uADmHVfh0bD-"
      },
      "cell_type": "code",
      "source": [
        "sentiment = 'positive'\n",
        "\n",
        "train_data = get_training_data(sentiment)\n",
        "model_path = get_model_out_path(sentiment)\n",
        "# For DEmo Purposes I have taken 3 iterations you can train the model as you want\n",
        "train(train_data, model_path, n_iter=3, model=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "NcIT2QZf0bD_"
      },
      "cell_type": "code",
      "source": [
        "sentiment = 'negative'\n",
        "\n",
        "train_data = get_training_data(sentiment)\n",
        "model_path = get_model_out_path(sentiment)\n",
        "\n",
        "train(train_data, model_path, n_iter=3, model=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlUSnN3F0bD_"
      },
      "cell_type": "markdown",
      "source": [
        "### Predicting with the trained Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QwYX9NvN0bEA"
      },
      "cell_type": "code",
      "source": [
        "def predict_entities(text, model):\n",
        "    doc = model(text)\n",
        "    ent_array = []\n",
        "    for ent in doc.ents:\n",
        "        start = text.find(ent.text)\n",
        "        end = start + len(ent.text)\n",
        "        new_int = [start, end, ent.label_]\n",
        "        if new_int not in ent_array:\n",
        "            ent_array.append([start, end, ent.label_])\n",
        "    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
        "    return selected_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ejYzakwm0bEA"
      },
      "cell_type": "code",
      "source": [
        "selected_texts = []\n",
        "MODELS_BASE_PATH = '../input/tse-spacy-model/models/'\n",
        "\n",
        "if MODELS_BASE_PATH is not None:\n",
        "    print(\"Loading Models  from \", MODELS_BASE_PATH)\n",
        "    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n",
        "    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n",
        "\n",
        "    for index, row in df_test.iterrows():\n",
        "        text = row.text\n",
        "        output_str = \"\"\n",
        "        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n",
        "            selected_texts.append(text)\n",
        "        elif row.sentiment == 'positive':\n",
        "            selected_texts.append(predict_entities(text, model_pos))\n",
        "        else:\n",
        "            selected_texts.append(predict_entities(text, model_neg))\n",
        "\n",
        "df_test['selected_text'] = selected_texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ypitkm6D0bEA"
      },
      "cell_type": "code",
      "source": [
        "df_submission['selected_text'] = df_test['selected_text']\n",
        "df_submission.to_csv(\"submission.csv\", index=False)\n",
        "display(df_submission.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "J3A5FL-G0bEA"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}